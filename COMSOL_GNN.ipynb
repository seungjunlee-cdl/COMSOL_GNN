{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e421cfdf-fcce-4b34-8e7c-81554e54f227",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.collections import PolyCollection\n",
    "from matplotlib.tri import Triangulation\n",
    "from IPython.display import display, clear_output\n",
    "import os\n",
    "import wandb\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11572106-b5a2-46d6-87fe-f9750c03938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplot(coordinates,elem,values,figure_size):\n",
    "    tri_obj = Triangulation(coordinates[:,0],coordinates[:,1],elem-1)\n",
    "    fig = plt.figure(figsize=figure_size)\n",
    "    ax=fig.add_subplot(1,1,1)\n",
    "    ax.triplot(tri_obj,c='black')\n",
    "    ax.tricontourf(tri_obj,values.reshape(-1),levels=np.linspace(-0.01,1.01,51),cmap='Greys')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.gcf().set_facecolor(\"white\")\n",
    "    \n",
    "def collate(samples):\n",
    "    graphs, labels = map(list, zip(*samples))\n",
    "    batched_graph = dgl.batch(graphs)\n",
    "    num_nodes = batched_graph.batch_num_nodes()\n",
    "    return batched_graph, torch.tensor(np.vstack(labels))\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for disjoint_graphs_test, output_features_test in loader:\n",
    "            predictions_test = model(disjoint_graphs_test.to('cuda'), disjoint_graphs_test.ndata['Features'].to('cuda'))\n",
    "            loss_eval = torch.nn.L1Loss()(output_features_test.to('cuda'), predictions_test)\n",
    "            loss_eval = loss_eval.to('cpu').detach().numpy()\n",
    "            break\n",
    "    return loss_eval\n",
    "\n",
    "def plot_save(model,epoch,path):\n",
    "    data_amount = [141,280,153,125,252,125,141,280,153]\n",
    "    foldermat = ['C_C','C_N','C_R','L_C','L_N','L_R','M_C','M_N','M_R']\n",
    "    \n",
    "    os.makedirs(path + '/' + '%d_epoch'%(epoch), exist_ok=True)\n",
    "    \n",
    "    for folder_name in foldermat:\n",
    "        folder_ind = foldermat.index(folder_name)\n",
    "        num_data = data_amount[folder_ind]\n",
    "        with open(folder_name + '/' + folder_name + '_test_index.bin','rb') as test_ind:\n",
    "            plot_test_ind = np.fromfile(test_ind,dtype = 'float32',count=-1).astype(int)\n",
    "            plot_test_ind = plot_test_ind-1\n",
    "        with open(folder_name + '/' + 'edgeinfo.bin','rb') as elen:\n",
    "            edge_num_mat = np.fromfile(elen,dtype = 'float32',count=-1).astype(int)\n",
    "        with open(folder_name + '/infomat.bin','rb') as im:\n",
    "            infomat = np.fromfile(im,dtype = 'float32',count=-1).reshape(num_data,13).transpose([1,0])\n",
    "        with open(folder_name + '/' + 'ELEMinfo.bin','rb') as elem:\n",
    "            elemmat = np.fromfile(elem,dtype = 'float32',count=-1).astype(int)\n",
    "            \n",
    "        randind = np.random.choice(plot_test_ind, replace=False)\n",
    "        node_num = int(infomat[0,randind])\n",
    "        \n",
    "        with open(folder_name + '/' + 'A_features_%d.bin'%(randind+1),'rb') as af_plot:\n",
    "            afmat_plot = np.fromfile(af_plot,dtype='float32',count=-1).reshape(node_num+9,node_num).transpose([1,0])\n",
    "            afmat_plot[:,-1:] = np.clip(afmat_plot[:,-1:],0,1)\n",
    "\n",
    "        with open(folder_name + '/' + 'edges_%d.bin'%(randind+1),'rb') as em_plot:\n",
    "            edge_mat_plot = np.fromfile(em_plot,dtype='float32',count=-1).reshape(2,edge_num_mat[randind]).transpose([1,0])\n",
    "            edge_mat_plot = edge_mat_plot.astype(int)\n",
    "            edge_mat_plot += -1\n",
    "            \n",
    "        with open(folder_name + '/' + 'ELEM_%d.bin'%(randind+1),'rb') as elem_plot:\n",
    "            ELEM_plot = np.fromfile(elem_plot,dtype='float32',count=-1).reshape(3,elemmat[randind]).transpose([1,0]).astype('int')\n",
    "        \n",
    "        graph_plot = dgl.graph((edge_mat_plot[:,0],edge_mat_plot[:,1]))\n",
    "        graph_plot.ndata['Features'] = torch.tensor(afmat_plot[:,-9:-1])\n",
    "        graph_plot = dgl.add_self_loop(graph_plot)\n",
    "        graph_plot = dgl.to_bidirected(graph_plot,copy_ndata = True)\n",
    "        \n",
    "        model = model.to('cpu')\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions_plot = model(graph_plot,graph_plot.ndata['Features'])\n",
    "        \n",
    "        plot_hight = np.max(afmat_plot[:,-4:-3])-np.min(afmat_plot[:,-4:-3])\n",
    "        plot_width = np.max(afmat_plot[:,-3:-2])-np.min(afmat_plot[:,-3:-2])\n",
    "        \n",
    "        triplot(afmat_plot[:,-4:-2],ELEM_plot,afmat_plot[:,-1:],(plot_hight,plot_width))\n",
    "        plt.savefig(path + '/' + '%d_epoch'%(epoch) + '/' + folder_name+'_TO.jpg')\n",
    "        plt.close()\n",
    "        triplot(afmat_plot[:,-4:-2],ELEM_plot,predictions_plot,(plot_hight,plot_width))\n",
    "        plt.savefig(path + '/' + '%d_epoch'%(epoch) + '/' + folder_name+'_DL.jpg')\n",
    "        plt.close()\n",
    "        \n",
    "    model = model.to('cuda')\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "    \n",
    "def reg_layer(layer_num):\n",
    "    assert len(np.array(layer_num).shape) == 1\n",
    "    num_reg_layer = len(layer_num)\n",
    "    namespace = []\n",
    "    for ln in range(len(layer_num)):\n",
    "        namespace.append('graph_conv%d'%(layer_num[ln])+'.weight')\n",
    "    return namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67f88d54-8ef2-4a1c-b935-71c1ea6e6af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mesh2Graph(dgl.data.DGLDataset):\n",
    "    def __init__(self,is_train):\n",
    "        self.is_train = is_train\n",
    "        super().__init__(name='MESH2GRAPH'+ '__' + is_train)\n",
    "        \n",
    "    def process(self):\n",
    "        self.graphs = []\n",
    "        self.labels = []\n",
    "        \n",
    "        path = os.getcwd()\n",
    "        folder_list = [name for name in os.listdir(path) if os.path.isdir(os.path.join(path, name)) and not name.startswith('.')]\n",
    "        folder_list_sort = ['C_C','C_N','C_R','L_C','L_N','L_R','M_C','M_N','M_R']\n",
    "        data_amount = [141,280,153,125,252,125,141,280,153]\n",
    "\n",
    "        for folder_iter in range(len(folder_list)):\n",
    "            folder_name = folder_list[folder_iter]\n",
    "            ind_folder = folder_list_sort.index(folder_name)\n",
    "            num_data = data_amount[ind_folder]\n",
    "\n",
    "            with open(folder_name + '/' + 'edgeinfo.bin','rb') as elen:\n",
    "                edge_num = np.fromfile(elen,dtype = 'float32',count=-1).astype(int)\n",
    "\n",
    "            with open(folder_name + '/' + folder_name + '_test_index.bin','rb') as pind:\n",
    "                part_test_ind = np.fromfile(pind,dtype = 'float32',count=-1).astype(int)\n",
    "                part_test_ind = part_test_ind-1\n",
    "\n",
    "            with open(folder_name + '/infomat.bin','rb') as im:\n",
    "                infomat = np.fromfile(im,dtype = 'float32',count=-1).reshape(num_data,13).transpose([1,0])\n",
    "\n",
    "            for data_iter in range(num_data):\n",
    "                node_num = int(infomat[0,data_iter])\n",
    "\n",
    "                with open(folder_list[folder_iter] + '/' + 'A_features_%d.bin'%(data_iter+1),'rb') as af:\n",
    "                    afmat = np.fromfile(af,dtype='float32',count=-1).reshape(node_num+9,node_num).transpose([1,0])\n",
    "                    afmat[:,-1:] = np.clip(afmat[:,-1:],0,1)\n",
    "\n",
    "                with open(folder_list[folder_iter] + '/' + 'edges_%d.bin'%(data_iter+1),'rb') as em:\n",
    "                    edge_mat = np.fromfile(em,dtype='float32',count=-1).reshape(2,edge_num[data_iter]).transpose([1,0])\n",
    "                    edge_mat = edge_mat.astype(int)\n",
    "                    edge_mat += -1\n",
    "                    \n",
    "                node_features = afmat[0:,node_num:-1]\n",
    "                node_label = afmat[0:,-1:]\n",
    "                \n",
    "                g = dgl.graph((edge_mat[:,0],edge_mat[:,1]))\n",
    "                g.ndata['Features'] = torch.tensor(node_features)\n",
    "                g = dgl.add_self_loop(g)\n",
    "                g = dgl.to_bidirected(g,copy_ndata = True)\n",
    "\n",
    "                clear_output(wait=True)\n",
    "                if (self.is_train is 'train') and (data_iter not in part_test_ind):\n",
    "                    self.graphs.append(g)\n",
    "                    self.labels.append(node_label)\n",
    "                elif (self.is_train is 'test') and (data_iter in part_test_ind):\n",
    "                    self.graphs.append(g)\n",
    "                    self.labels.append(node_label)\n",
    "                elif (self.is_train is 'total'):\n",
    "                    self.graphs.append(g)\n",
    "                    self.labels.append(node_label)\n",
    "                        \n",
    "                print(folder_name, g, g.device)\n",
    "                clear_output(wait=True)\n",
    "                    \n",
    "        print('Graph Representation Done')\n",
    "    def __getitem__(self, i):\n",
    "        return self.graphs[i], self.labels[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f123c119-97c4-4a01-b375-acb1b0c41767",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TOP_MODEL(torch.nn.Module):\n",
    "    def __init__(self, num_layers, num_hidden_features):\n",
    "        super().__init__()\n",
    "        assert num_layers%2 ==0, 'Number of Layers is not Even : Skip connection operation is obscure'\n",
    "        assert num_hidden_features < 512, 'Number of Filter is too Large'\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.num_hidden_features = num_hidden_features\n",
    "\n",
    "        for nl in range(1,self.num_layers+1):\n",
    "            if nl==1:\n",
    "                self.graph_conv1 = dgl.nn.pytorch.conv.GraphConv(in_feats=8,out_feats=self.num_hidden_features,bias=False)\n",
    "                self.bn1 = torch.nn.BatchNorm1d(num_features = self.num_hidden_features)\n",
    "                self.act1 = torch.nn.ReLU()\n",
    "            \n",
    "            elif nl in [8,16,17,25,32]:\n",
    "                in_GCN_tmp = \"self.graph_conv%d\"%(nl)\n",
    "                in_BN_tmp = \"self.bn%d\"%(nl)\n",
    "                in_ACT_tmp = \"self.act%d\"%(nl)\n",
    "                \n",
    "                GCN_tmp = \"dgl.nn.pytorch.conv.GraphConv(in_feats=self.num_hidden_features,out_feats=self.num_hidden_features,bias=False)\"\n",
    "                BN_tmp = \"torch.nn.BatchNorm1d(num_features = self.num_hidden_features)\"\n",
    "                ACT_tmp = \"torch.nn.ReLU()\"\n",
    "                \n",
    "                exec('%s = %s'%(in_GCN_tmp,GCN_tmp))\n",
    "                exec('%s = %s'%(in_BN_tmp,BN_tmp))\n",
    "                exec('%s = %s'%(in_ACT_tmp,ACT_tmp))\n",
    "            elif ((nl<=16) and (nl%2==0)) or ((nl>=17) and (nl%2==1)):\n",
    "                in_GCN_tmp = \"self.graph_conv%d\"%(nl)\n",
    "                in_DO_tmp = \"self.do%d\"%(nl)\n",
    "                in_ACT_tmp = \"self.act%d\"%(nl)\n",
    "\n",
    "                GCN_tmp = \"dgl.nn.pytorch.conv.GraphConv(in_feats=self.num_hidden_features,out_feats=self.num_hidden_features,bias=True)\"\n",
    "                DO_tmp = \"torch.nn.Dropout(p=0.2)\"\n",
    "                ACT_tmp = \"torch.nn.ReLU()\"\n",
    "\n",
    "                exec('%s = %s'%(in_GCN_tmp,GCN_tmp))\n",
    "                exec('%s = %s'%(in_DO_tmp,DO_tmp))\n",
    "                exec('%s = %s'%(in_ACT_tmp,ACT_tmp))\n",
    "            elif ((nl<=16) and (nl%2==1)) or ((nl>=17) and (nl%2==0)):\n",
    "                in_GCN_tmp = \"self.graph_conv%d\"%(nl)\n",
    "                in_ACT_tmp = \"self.act%d\"%(nl)\n",
    "\n",
    "                GCN_tmp = \"dgl.nn.pytorch.conv.GraphConv(in_feats=self.num_hidden_features,out_feats=self.num_hidden_features,bias=True)\"\n",
    "                ACT_tmp = \"torch.nn.ReLU()\"\n",
    "\n",
    "                exec('%s = %s'%(in_GCN_tmp,GCN_tmp))\n",
    "                exec('%s = %s'%(in_ACT_tmp,ACT_tmp))\n",
    "\n",
    "        self.graph_conv_last = dgl.nn.pytorch.conv.GraphConv(in_feats=self.num_hidden_features,out_feats=1,bias=True)\n",
    "        self.act_last = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, graphs, features):\n",
    "        for i in range(1,self.num_layers+1):\n",
    "            if i==1:\n",
    "                self.c1 = self.graph_conv1(graphs, features)\n",
    "                self.b1 = self.bn1(self.c1)            \n",
    "                self.a1 = self.act1(self.b1)\n",
    "            elif i in [8,16]:\n",
    "                exec('self.c%d = self.graph_conv%d(graphs, self.a%d)'%(i,i,i-1))\n",
    "                exec('self.b%d = self.bn%d(self.c%d)'%(i,i,i))\n",
    "                exec('self.a%d = self.act%d(self.b%d)'%(i,i,i))\n",
    "            elif (i%2==0) and (i<=16) and (i not in [8,16]):\n",
    "                exec('self.c%d = self.graph_conv%d(graphs, self.a%d)'%(i,i,i-1))\n",
    "                exec('self.d%d = self.do%d(self.c%d)'%(i,i,i))\n",
    "                exec('self.a%d = self.act%d(self.d%d)'%(i,i,i))\n",
    "            elif (i%2==1) and (i<=16) and (i not in [8,16]):\n",
    "                exec('self.c%d = self.graph_conv%d(graphs, self.a%d)'%(i,i,i-1))\n",
    "                exec('self.a%d = self.act%d(self.c%d)'%(i,i,i))\n",
    "            elif i in [17,25,32]:\n",
    "                exec('self.c%d = self.graph_conv%d(graphs, self.a%d)'%(i,i,i-1))\n",
    "                exec('self.b%d = self.bn%d(self.c%d)'%(i,i,i))\n",
    "                exec('self.skip%d = self.a%d + self.b%d'%(i,self.num_layers+1-i,i))\n",
    "                exec('self.a%d = self.act%d(self.skip%d)'%(i,i,i))\n",
    "            elif (i%2==0) and (i>=17) and (i not in [17,25,32]):\n",
    "                exec('self.c%d = self.graph_conv%d(graphs, self.a%d)'%(i,i,i-1))\n",
    "                exec('self.skip%d = self.a%d + self.c%d'%(i,self.num_layers+1-i,i))\n",
    "                exec('self.a%d = self.act%d(self.skip%d)'%(i,i,i))\n",
    "            elif (i%2==1) and (i>=17) and (i not in [17,25,32]):\n",
    "                exec('self.c%d = self.graph_conv%d(graphs, self.a%d)'%(i,i,i-1))\n",
    "                exec('self.d%d = self.do%d(self.c%d)'%(i,i,i))\n",
    "                exec('self.skip%d = self.a%d + self.d%d'%(i,self.num_layers+1-i,i))\n",
    "                exec('self.a%d = self.act%d(self.skip%d)'%(i,i,i))\n",
    "            \n",
    "        exec('self.c_last = self.graph_conv_last(graphs, self.a%d)'%(self.num_layers))\n",
    "        out = self.act_last(self.c_last)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "522f1914-bad2-4ad9-9cbe-0f3584ca07ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Representation Done\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Mesh2Graph('train')\n",
    "test_dataset =  Mesh2Graph('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "171a0be1-ef8b-4021-827a-fb676348397e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 32\n",
    "num_hidden_features = 128\n",
    "model = TOP_MODEL(num_layers,num_hidden_features)\n",
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "855744a6-8254-467d-b177-265dc5a8b2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = dgl.dataloading.pytorch.GraphDataLoader(train_dataset, collate_fn=collate, batch_size=128, shuffle=True)\n",
    "test_loader = dgl.dataloading.pytorch.GraphDataLoader(test_dataset, collate_fn=collate, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b9fa32d-8d52-4c1c-98a0-c649a97dedea",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,factor=0.9, patience=50, min_lr=1e-5, verbose=False)\n",
    "MAE_loss = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcfaafba-2be5-4af9-8866-1515f1e04712",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reg_layer_num = []\n",
    "for ln in range(1,num_layers+1):\n",
    "    if (ln%2==1) and (ln<=16) and (ln not in [1,8,16]):\n",
    "        reg_layer_num.append(ln)\n",
    "    elif (ln%2==0) and (ln>=17) and (ln not in [17,25,32]):\n",
    "        reg_layer_num.append(ln)\n",
    "reg_layer_namespace = reg_layer(reg_layer_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e701b0ef-2bb1-45b3-8860-7054d58e910e",
   "metadata": {},
   "outputs": [],
   "source": [
    "emax = 2000\n",
    "min_test_err = [1]\n",
    "modelsave_interval = 100\n",
    "plotsave_interval = 100\n",
    "l2reg_factor = 0.01\n",
    "experiment_name = \"GNN_comsol_L2reg_128bs\"\n",
    "wandb.init(project=\"GNN_bcs2opt\",group=experiment_name)\n",
    "config = wandb.config\n",
    "\n",
    "save_fig_path = '../Result_pictures/L2reg_128bs'\n",
    "save_interv_model_path = '../models/initial_try/L2reg_128bs'\n",
    "save_best_model_path = '../models/initial_try/best_save_L2reg_128bs'\n",
    "\n",
    "os.makedirs(save_fig_path, exist_ok=True)\n",
    "os.makedirs(save_interv_model_path, exist_ok=True)\n",
    "os.makedirs(save_best_model_path, exist_ok=True)\n",
    "\n",
    "for e in range(1,emax+1):\n",
    "    for batch_num, (disjoint_graphs, output_features) in enumerate(train_loader):\n",
    "        pred_features = model(disjoint_graphs.to('cuda'), disjoint_graphs.ndata['Features'].to('cuda'))\n",
    "        loss_training = MAE_loss(pred_features, output_features.to('cuda'))\n",
    "        loss_reg = 0\n",
    "        for parameter in model.named_parameters():\n",
    "            for i in range(len(reg_layer_namespace)):\n",
    "                if reg_layer_namespace[i] in parameter:\n",
    "                    loss_reg += torch.sum(parameter[1]**2)\n",
    "        loss_training = loss_training + l2reg_factor*loss_reg\n",
    "        optimizer.zero_grad()\n",
    "        loss_training.backward()\n",
    "        optimizer.step()\n",
    "        print('Epoch : %d     Batch : %d     Training loss : %f     reg loss : %f     Learning rate : %f'%(e,batch_num,loss_training,loss_reg,get_lr(optimizer)))\n",
    "        clear_output(wait = True)\n",
    "    loss_test = evaluate(model,test_loader)\n",
    "    scheduler.step(loss_test)\n",
    "    wandb.log({\"training_loss\":loss_training, \"test_loss\":loss_test})\n",
    "    \n",
    "    if e%plotsave_interval ==0:\n",
    "        plot_save(model,e,save_fig_path)   \n",
    "    if e%modelsave_interval == 0:\n",
    "        torch.save(model.state_dict(),save_interv_model_path + '/' + 'model_%d_epoch'%(e))\n",
    "    if min_test_err > loss_test:\n",
    "        torch.save(model.state_dict(),save_best_model_path + '/' + 'best_model')\n",
    "        min_test_err = copy.copy([loss_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4d4121-c45a-49b1-91b0-4a996641191f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load = TOP_MODEL(32,128)\n",
    "model_load.load_state_dict(torch.load(savemodel_path + 'model_test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0105f3c-034c-4ad3-8b8d-b90d72bdb45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_save(model_load,1,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e384b3f-5d1e-4107-ae1f-54656458fb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,32):\n",
    "    if ((i<=16) and (i%2==1)) or ((i>=17) and (i%2==0)):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a896812-56f9-4370-860b-c49f6ab05b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "for disjoint_graphs, output_features in train_loader:\n",
    "    test_output = model(disjoint_graphs, disjoint_graphs.ndata['Features'])\n",
    "    print(test_output, output_features)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b73bd67-f692-490c-9f60-acbef53ec4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in dir(train_dataset):\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4114b5-eef7-458b-8ce7-a925395d4bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(g.edges(form = 'all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7487ca53-208c-4a0c-86ff-be899889d4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.ndata['x'] = torch.ones(g.num_nodes(),4)\n",
    "g.ndata['y'] = torch.ones(g.num_nodes(),4)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f8d025-3cae-402a-aa16-d0ec40072533",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dgl.data.CoraGraphDataset()\n",
    "print('Number of categories:', dataset.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58309ffc-9957-4839-b027-acec63e3196c",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = dataset[0]\n",
    "print(g.ndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c012f855-393e-4bab-8cc2-38583c2e8812",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
